# Bhavanavishkar - Speech Emotion Recognition
   Human and machine interaction is an area where computer science is looking forward in various new upcoming technologies and taking them to the next advance level. Speech Emotion Recognition contribute in grater extent in this field. As the speech produces by humans helps us to understand and predict what is the certain emotion of a human being in a particular situation and thus can be developed.

# Why Emotion   
  Emotion awareness improves customer experience. Which helps us to predict what exact feedback a customer has on a particular product what are the various problems, difficulties he/she faced. This will lead is better designing of a product and carrying out it in an efficient and effective manner. 
 
 Humans are in use to express emotions to computers all the time whenever they come in touch with it. This has lead building of Human Computer interface to a next level where computers/machines can exactly understand the  real time  emotion state of a person and can handle the different programs accordingly and this eventually makes a better customer experience.
  
  On the same root, if a machine knowns the exact emotion state of a student then by assessing those emotions it can present the perfect match to a student maybe it be in notes, videos, slides, etc format which will create a fruitful Computer Aid Learning Technology which is the exact need in this pandemic situation.
  
 Speech Emotion Recognition can be used in various fields like gamer industry to understand the current emotion of a gamer which helps to known different frustration points while playing which can be further be improved upon. Human Emotion plays a vital role in a Marketing field which guide us to known the view reactions. This also can be implemented in automotive industry to avoid road rage  to make driver experience safer.

 
![Screenshot (1214)](https://user-images.githubusercontent.com/64628671/90512479-db053500-e17b-11ea-92cf-3877f01986bd.png)

For the advanced usage of the speech emotion recognition, instead of using feature engineering, deep learning is used. Deep learning includes both, the feature extraction and learning.

# Emotion Representation 
 Categories –    
•	Anger
•	Disgust
•	Fear
•	Happiness
•	Sadness
•	Surprise
•	Neutral

# Ideology
![Screenshot (1218)](https://user-images.githubusercontent.com/64628671/90513339-1d7b4180-e17d-11ea-9a02-9fd85eb7a654.png)

# Multimode Speech Emotion Recognition
![Screenshot (1221)](https://user-images.githubusercontent.com/64628671/90513550-72b75300-e17d-11ea-9227-35d8e934cedf.png)

# Data set
Emotion Dimensions:
•	Activation
•	Valence
•	Dominance


Emotion Categories:
•	Anger
•	Happiness
•	Sadness
•	Neutral
•	Fear, Disgust, Surprise

# Music App suggesting music based on persons mood 

   Speech Emotion Recognition has a grate application in Music stream. Using human emotion one can easily find what exact music or song he/she wants to here rather than keeping viewing on various songs and wasting time on it. Thus using emotion this music app can predict your emotional mood and recommend you the best suitable song. Thus the same process can be carried out for recommending the podcast, music and even music as per the persons emotion predicted as per speech. This will lead the music and human interaction to a greater extent. Providing annotations and emotion judgements is difficult due to the difference in interpretation from person to person but now using a CNN this has helped to train the machine to predict the exact emotion of human. 
   
# Result of CNN model
   Loss vs Epoch
   
   ![Screenshot (1226)](https://user-images.githubusercontent.com/64628671/90514167-70a1c400-e17e-11ea-8970-e5e5519010be.png)
   
   









